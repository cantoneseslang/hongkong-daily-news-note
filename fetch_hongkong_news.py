#!/usr/bin/env python3
"""
é¦™æ¸¯ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3ã¤ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã‹ã‚‰ä¸¦åˆ—ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã—ã€çµ±åˆã—ã¾ã™
"""

import requests
import json
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict
import time

# HKTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ï¼ˆUTC+8ï¼‰
HKT = timezone(timedelta(hours=8))

class HongKongNewsAPI:
    def __init__(self, config_path: str = "config.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        self.api_keys = self.config['api_keys']
        self.settings = self.config['settings']
        
    def fetch_newsdata_io(self) -> List[Dict]:
        """NewsData.ioã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—"""
        print("ğŸ“° NewsData.io ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­...")
        url = "https://newsdata.io/api/1/news"
        params = {
            'apikey': self.api_keys['newsdata_io'],
            'country': 'hk',
            'language': 'en',
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])
                print(f"  âœ… {len(results)}ä»¶å–å¾—")
                return [{
                    'title': item.get('title'),
                    'description': item.get('description'),
                    'url': item.get('link'),
                    'published_at': item.get('pubDate'),
                    'source': item.get('source_id', 'NewsData.io'),
                    'api_source': 'newsdata_io'
                } for item in results[:10]]
            else:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return []
        except Exception as e:
            print(f"  âŒ ä¾‹å¤–: {e}")
            return []
    
    def fetch_world_news_api(self) -> List[Dict]:
        """World News APIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—"""
        print("ğŸ“° World News API ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­...")
        url = "https://api.worldnewsapi.com/search-news"
        
        yesterday = (datetime.now(HKT) - timedelta(days=1)).strftime('%Y-%m-%d')
        today = datetime.now(HKT).strftime('%Y-%m-%d')
        
        params = {
            'api-key': self.api_keys['world_news_api'],
            'source-country': 'hk',
            'language': 'en',
            'earliest-publish-date': yesterday,
            'latest-publish-date': today,
            'number': 10,
            'sort': 'publish-time',
            'sort-direction': 'desc'
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                news = data.get('news', [])
                print(f"  âœ… {len(news)}ä»¶å–å¾—")
                return [{
                    'title': item.get('title'),
                    'description': item.get('text', '')[:500],
                    'url': item.get('url'),
                    'published_at': item.get('publish_date'),
                    'source': item.get('source', 'World News API'),
                    'api_source': 'world_news_api'
                } for item in news]
            else:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return []
        except Exception as e:
            print(f"  âŒ ä¾‹å¤–: {e}")
            return []
    
    def fetch_news_api(self) -> List[Dict]:
        """News APIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—"""
        print("ğŸ“° News API ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­...")
        url = "https://newsapi.org/v2/top-headlines"
        params = {
            'apiKey': self.api_keys['news_api'],
            'country': 'hk',
            'pageSize': 10
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                articles = data.get('articles', [])
                print(f"  âœ… {len(articles)}ä»¶å–å¾—")
                return [{
                    'title': item.get('title'),
                    'description': item.get('description'),
                    'url': item.get('url'),
                    'published_at': item.get('publishedAt'),
                    'source': item.get('source', {}).get('name', 'News API'),
                    'api_source': 'news_api'
                } for item in articles]
            else:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return []
        except Exception as e:
            print(f"  âŒ ä¾‹å¤–: {e}")
            return []
    
    def is_hongkong_related(self, news: Dict) -> bool:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒé¦™æ¸¯é–¢é€£ã‹ãƒã‚§ãƒƒã‚¯"""
        # Hong Kong Free Pressã‚’é™¤å¤–
        url = news.get('url', '').lower()
        if 'hongkongfp.com' in url:
            return False
        
        keywords = [
            # åŸºæœ¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            'hong kong', 'hongkong', 'hk', 'é¦™æ¸¯', 'æ¸¯',
            
            # ä¸»è¦åœ°åŒºãƒ»åœ°å
            'central', 'kowloon', 'wan chai', 'causeway bay', 'tai koo', 'admiralty',
            'tsim sha tsui', 'victoria harbour', 'lantau', 'kwai chung', 'tin shui wai', 
            'tiu keng leng', 'sha tin', 'mong kok', 'yau ma tei', 'jordan', 'tai po',
            'ä¸­ç’°', 'ä¹é¾', 'ç£ä»”', 'éŠ…é‘¼ç£', 'å¤ªå¤', 'é‡‘é˜', 'å°–æ²™å’€', 'æ—ºè§’',
            'æ²¹éº»åœ°', 'ä½æ•¦', 'å¤§åŸ”', 'è‘µæ¶Œ', 'å¤©æ°´åœ', 'èª¿æ™¯å¶º', 'æ²™ç”°',
            'ç¶­å¤šåˆ©äºæ¸¯', 'å¤§å¶¼å±±', 'é’è¡£', 'å±¯é–€', 'å…ƒæœ—', 'ä¸Šæ°´', 'ç²‰å¶º',
            
            # äº¤é€šãƒ»ã‚¤ãƒ³ãƒ•ãƒ©
            'mtr', 'æ¸¯éµ', 'hong kong international airport', 'é¦™æ¸¯åœ‹éš›æ©Ÿå ´',
            'hong kong tramways', 'é¦™æ¸¯é›»è»Š', 'star ferry', 'å¤©æ˜Ÿå°è¼ª',
            'hong kong zhuhai macau bridge', 'æ¸¯ç æ¾³å¤§æ©‹', 'high speed rail', 'é«˜éµ',
            
            # æ”¿æ²»ãƒ»è¡Œæ”¿ï¼ˆæœ€æ–°ï¼‰
            'legco', 'legislative council', 'ç«‹æ³•æœƒ', 'hksar', 'é¦™æ¸¯ç‰¹åˆ¥è¡Œæ”¿å€',
            'john lee', 'æå®¶è¶…', 'è¡Œæ”¿é•·å®˜', 'chief executive',
            'hong kong government', 'é¦™æ¸¯æ”¿åºœ', 'hong kong police', 'é¦™æ¸¯è­¦å¯Ÿ',
            'hong kong observatory', 'é¦™æ¸¯å¤©æ–‡å°', 'hong kong monetary authority', 'é‡‘ç®¡å±€',
            
            # çµŒæ¸ˆãƒ»é‡‘è
            'hkex', 'hong kong stock exchange', 'é¦™æ¸¯äº¤æ˜“æ‰€', 'hong kong dollar', 'æ¸¯å¹£',
            'greater bay area', 'ç²µæ¸¯æ¾³å¤§ç£å€', 'hong kong finance', 'é¦™æ¸¯é‡‘è',
            
            # æ–‡åŒ–ãƒ»è¦³å…‰
            'm+ museum', 'è¥¿ä¹æ–‡åŒ–å€', 'west kowloon cultural district', 'hong kong disneyland',
            'é¦™æ¸¯è¿ªå£«å°¼', 'ocean park', 'æµ·æ´‹å…¬åœ’', 'hong kong arts festival', 'é¦™æ¸¯è—è¡“ç¯€',
            'hong kong international film festival', 'é¦™æ¸¯åœ‹éš›é›»å½±ç¯€',
            
            # æ•™è‚²ãƒ»å¤§å­¦
            'university of hong kong', 'é¦™æ¸¯å¤§å­¸', 'chinese university of hong kong', 'é¦™æ¸¯ä¸­æ–‡å¤§å­¸',
            'hong kong university of science and technology', 'é¦™æ¸¯ç§‘æŠ€å¤§å­¸',
            'city university of hong kong', 'é¦™æ¸¯åŸå¸‚å¤§å­¸',
            
            # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹
            'scmp', 'south china morning post', 'å—è¯æ—©å ±', 'rthk', 'é¦™æ¸¯é›»å°',
            'chinadaily', 'hket', 'the standard', 'ming pao', 'æ˜å ±',
            'hong kong free press', 'hk01', 'now news', 'nowæ–°è'
        ]
        
        text = f"{news.get('title', '')} {news.get('description', '')}".lower()
        
        # é¦™æ¸¯é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for keyword in keywords:
            if keyword in text:
                return True
        
        # URLã«é¦™æ¸¯é–¢é€£ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆHKFPã¯é™¤å¤–æ¸ˆã¿ï¼‰
        hk_domains = ['scmp.com', 'thestandard.com.hk', 
                      'rthk.hk', 'chinadailyhk.com', 'hk01.com']
        for domain in hk_domains:
            if domain in url:
                return True
        
        return False
    
    def fetch_all_news(self) -> List[Dict]:
        """3ã¤ã®APIã‹ã‚‰ä¸¦åˆ—ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—"""
        print("\nğŸš€ é¦™æ¸¯ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–‹å§‹")
        print("=" * 60)
        
        all_news = []
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(self.fetch_newsdata_io): 'newsdata_io',
                executor.submit(self.fetch_world_news_api): 'world_news_api',
                executor.submit(self.fetch_news_api): 'news_api'
            }
            
            for future in as_completed(futures):
                api_name = futures[future]
                try:
                    results = future.result()
                    all_news.extend(results)
                except Exception as e:
                    print(f"  âŒ {api_name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("=" * 60)
        print(f"âœ… åˆè¨ˆ {len(all_news)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
        
        # é‡è¤‡é™¤å»ï¼ˆURLãƒ™ãƒ¼ã‚¹ï¼‰
        seen_urls = set()
        unique_news = []
        for news in all_news:
            if news['url'] and news['url'] not in seen_urls:
                seen_urls.add(news['url'])
                unique_news.append(news)
        
        print(f"ğŸ“Š é‡è¤‡é™¤å»å¾Œ: {len(unique_news)}ä»¶")
        
        # é¦™æ¸¯é–¢é€£ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        hongkong_news = [news for news in unique_news if self.is_hongkong_related(news)]
        print(f"ğŸ‡­ğŸ‡° é¦™æ¸¯é–¢é€£: {len(hongkong_news)}ä»¶\n")
        
        return hongkong_news
    
    def save_raw_news(self, news: List[Dict], output_path: str = None):
        """å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’JSONå½¢å¼ã§ä¿å­˜"""
        if output_path is None:
            timestamp = datetime.now(HKT).strftime('%Y-%m-%d_%H-%M-%S')
            output_path = f"daily-articles/raw_news_{timestamp}.json"
        
        data = {
            'fetch_time': datetime.now(HKT).isoformat(),
            'total_count': len(news),
            'news': news
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¿å­˜: {output_path}")
        return output_path

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    api = HongKongNewsAPI()
    news = api.fetch_all_news()
    
    if news:
        saved_path = api.save_raw_news(news)
        print(f"\nâœ… å–å¾—å®Œäº†ï¼")
        print(f"ğŸ“ ä¿å­˜å…ˆ: {saved_path}")
        
        # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        print("\nğŸ“‹ å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæœ€åˆã®3ä»¶ï¼‰:")
        for i, item in enumerate(news[:3], 1):
            print(f"\n{i}. {item['title']}")
            print(f"   ã‚½ãƒ¼ã‚¹: {item['source']} ({item['api_source']})")
            print(f"   URL: {item['url']}")
    else:
        print("\nâŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

